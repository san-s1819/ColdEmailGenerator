{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1477350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       First Name Last Name            Email Source          Lead Title  \\\n",
      "count         249       249                     249                 249   \n",
      "unique        183       235                     249                 182   \n",
      "top         David       Lee  dtrosclair@vetjobs.org  Operations Manager   \n",
      "freq            8         3                       1                  12   \n",
      "\n",
      "                                         Lead Linkedin Company Name  \\\n",
      "count                                              249          249   \n",
      "unique                                             249          138   \n",
      "top     https://www.linkedin.com/in/danielle-trosclair     Gray AES   \n",
      "freq                                                 1            5   \n",
      "\n",
      "                                        Company Linkedin  \\\n",
      "count                                                249   \n",
      "unique                                               136   \n",
      "top     https://www.linkedin.com/company/aret-associates   \n",
      "freq                                                   5   \n",
      "\n",
      "                        Website           Job Title  \\\n",
      "count                       249                 249   \n",
      "unique                      140                 113   \n",
      "top     http://www.grayaes.com/  Operations Manager   \n",
      "freq                          5                  20   \n",
      "\n",
      "                                                  Job Url Job Count  \n",
      "count                                                 249       249  \n",
      "unique                                                156        58  \n",
      "top     https://www.careerbuilder.com/job/J3N77G6ZF14G...      200+  \n",
      "freq                                                    3        19  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from crawl4ai import AsyncWebCrawler, CrawlerRunConfig\n",
    "import fireworks.client\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "\n",
    "INPUT_FILE = \"S:/Portfolio/ColdEmailGenerator/Companies_Hiring_Tech_Roles.xlsx\"  # Replace with your actual Excel file path\n",
    "RESUME_FILE = \"S:/Portfolio/ColdEmailGenerator/Resumeforcoldemail.txt\"  # Replace with your actual resume file path\n",
    "\n",
    "    # 1. Read input files\n",
    "try:\n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "    print(df.describe())\n",
    "    with open(RESUME_FILE, \"r\") as f:\n",
    "        resume_content = f.read()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a9a31d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m    \u001b[38;5;28mprint\u001b[39m(results_dict.json())\n\u001b[32m     18\u001b[39m    contexts = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     19\u001b[39m        [\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([x[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m], x[\u001b[33m\"\u001b[39m\u001b[33msnippet\u001b[39m\u001b[33m\"\u001b[39m], x[\u001b[33m\"\u001b[39m\u001b[33mlink\u001b[39m\u001b[33m\"\u001b[39m]]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results_dict]\n\u001b[32m     20\u001b[39m    )\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mweb_search\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNathan\tBallinger Sutphen corp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mweb_search\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     11\u001b[39m search = GoogleSearch({\n\u001b[32m     12\u001b[39m     **serpapi_params,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mq\u001b[39m\u001b[33m\"\u001b[39m: query,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m \n\u001b[32m     15\u001b[39m })\n\u001b[32m     16\u001b[39m results_dict = search.get_dict()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults_dict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m())\n\u001b[32m     18\u001b[39m contexts = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     19\u001b[39m     [\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([x[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m], x[\u001b[33m\"\u001b[39m\u001b[33msnippet\u001b[39m\u001b[33m\"\u001b[39m], x[\u001b[33m\"\u001b[39m\u001b[33mlink\u001b[39m\u001b[33m\"\u001b[39m]]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results_dict]\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'json'"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "serpapi_params = {\n",
    "    \"engine\": \"google\",\n",
    "    \"api_key\": os.getenv(\"SERPAPI_KEY\")\n",
    "}\n",
    "\n",
    "def web_search(query: str):\n",
    "   \"\"\"Finds the correct LinkedIn profile using a specific search query and company URLs.\"\"\"\n",
    "   search = GoogleSearch({\n",
    "       **serpapi_params,\n",
    "       \"q\": query,\n",
    "       \"num\": 1 \n",
    "   })\n",
    "   results_dict = search.get_dict()\n",
    "   print(results_dict.json())\n",
    "   contexts = \"\\n---\\n\".join(\n",
    "       [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results_dict]\n",
    "   )\n",
    "web_search(\"Nathan\tBallinger Sutphen corp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529a5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
